{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file('person.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the face encodings(array of features extracted)\n",
    "face_encodings = face_recognition.face_encodings(image)\n",
    "face_encodings = face_encodings[0] # since only 1 face in image\n",
    "face_encodings.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20855853  0.0184522   0.05200072 -0.01912919 -0.02748842 -0.01855104\n",
      " -0.02725516 -0.01845019  0.19835594 -0.01124574  0.19645661  0.01600675\n",
      " -0.15621808 -0.08862403 -0.0091515   0.11604415 -0.12597208 -0.14229299\n",
      " -0.035728   -0.03505832  0.03726103  0.03980883 -0.07782646  0.07926033\n",
      " -0.14744233 -0.34706163 -0.10856134 -0.12216796  0.01723716 -0.11650686\n",
      "  0.06511277 -0.0390022  -0.18297048 -0.10930696  0.06847559  0.12637655\n",
      " -0.05037962 -0.09572256  0.13429841 -0.00703445 -0.16005877 -0.05573079\n",
      "  0.08435313  0.27441859  0.13435349  0.08523716  0.00496124 -0.1124642\n",
      "  0.16313255 -0.27373862  0.08402468  0.1012895   0.1534484   0.10832095\n",
      "  0.11609225 -0.09201854  0.07474772  0.25488397 -0.30816698  0.10207565\n",
      "  0.00198591 -0.01495523  0.03411689 -0.02620056  0.21705677  0.14441347\n",
      " -0.1109332  -0.12751676  0.17208117 -0.16183108 -0.04968159  0.12839442\n",
      " -0.03207503 -0.26411179 -0.31615108  0.07128873  0.3626399   0.18028158\n",
      " -0.13117115 -0.01013258 -0.05811105 -0.00737814  0.03560942  0.03457591\n",
      " -0.09948467 -0.06623525 -0.05779979 -0.01711867  0.24389176  0.12510219\n",
      "  0.00310593  0.16942376 -0.01417204 -0.02782676  0.00143114  0.06574455\n",
      " -0.10071307  0.00664655 -0.07640259 -0.06614346  0.03114726  0.03002056\n",
      "  0.07674081  0.13323893 -0.21063031  0.15302023 -0.0154897  -0.04833614\n",
      "  0.00523048 -0.02149034 -0.06463669  0.01915043  0.14195834 -0.29341805\n",
      "  0.22209305  0.12297855  0.04837457  0.1562109   0.00215635  0.00968098\n",
      " -0.03717984 -0.11729006 -0.17494753 -0.01424964  0.05999146 -0.07590412\n",
      "  0.07595525 -0.00694484]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings) == 0:\n",
    "    print('NO faces were found.')\n",
    "else:\n",
    "    # Grab the first face encoding ==> face_encodings[0]\n",
    "    first_face_encoding = face_encodings\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
